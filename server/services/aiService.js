import { getAIConfig, validateAIConfig } from '../config/ai.js';

// AI Service ƒë·ªÉ x·ª≠ l√Ω c√°c lo·∫°i AI kh√°c nhau
export class AIService {
  constructor() {
    this.config = getAIConfig();
    this.isValid = validateAIConfig();
    console.log('AIService constructor called');
    console.log('isValid:', this.isValid);
    console.log('provider:', this.config.provider);
  }

  // G·ªçi OpenAI API
  async callOpenAI(message, systemPrompt) {
    try {
      const response = await fetch(`${this.config.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: this.config.model,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          max_tokens: this.config.maxTokens,
          temperature: this.config.temperature
        })
      });

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error) {
      console.error('OpenAI API Error:', error);
      throw error;
    }
  }

  // G·ªçi Local AI (vLLM, Ollama, etc.)
  async callLocalAI(message, systemPrompt) {
    try {
      const headers = {
        'Content-Type': 'application/json'
      };

      // Th√™m API key n·∫øu c√≥
      if (this.config.apiKey) {
        headers['Authorization'] = `Bearer ${this.config.apiKey}`;
      }

      const response = await fetch(`${this.config.baseURL}/chat/completions`, {
        method: 'POST',
        headers,
        body: JSON.stringify({
          model: this.config.model,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          max_tokens: this.config.maxTokens,
          temperature: this.config.temperature
        })
      });

      if (!response.ok) {
        throw new Error(`Local AI API error: ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error) {
      console.error('Local AI API Error:', error);
      throw error;
    }
  }

  // G·ªçi Local AI v·ªõi streaming
  async callLocalAIStream(message, systemPrompt, onChunk) {
    try {
      const headers = {
        'Content-Type': 'application/json'
      };

      // Th√™m API key n·∫øu c√≥
      if (this.config.apiKey) {
        headers['Authorization'] = `Bearer ${this.config.apiKey}`;
      }

      const response = await fetch(`${this.config.baseURL}/chat/completions`, {
        method: 'POST',
        headers,
        body: JSON.stringify({
          model: this.config.model,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          max_tokens: this.config.maxTokens,
          temperature: this.config.temperature,
          stream: true
        })
      });

      if (!response.ok) {
        throw new Error(`Local AI API error: ${response.status}`);
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop(); // Keep incomplete line in buffer

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') {
              return;
            }
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                onChunk(content);
              }
            } catch (e) {
              console.log('Parse error in streaming:', e.message);
              console.log('Raw data:', data);
              // Ignore parsing errors for incomplete chunks
            }
          }
        }
      }
    } catch (error) {
      console.error('Local AI Streaming Error:', error);
      throw error;
    }
  }

  // Main method ƒë·ªÉ g·ªçi AI
  async generateResponse(message, systemPrompt) {
    if (!this.isValid && this.config.provider === 'openai') {
      return this.getFallbackResponse();
    }

    try {
      if (this.config.provider === 'localai') {
        return await this.callLocalAI(message, systemPrompt);
      } else {
        return await this.callOpenAI(message, systemPrompt);
      }
    } catch (error) {
      console.error('AI Service Error:', error);
      return this.getFallbackResponse();
    }
  }

  // Streaming method ƒë·ªÉ g·ªçi AI
  async generateStreamResponse(message, systemPrompt, onChunk) {
    console.log('generateStreamResponse called');
    console.log('isValid:', this.isValid);
    console.log('provider:', this.config.provider);
    
    if (!this.isValid) {
      console.log('Using fallback response due to !isValid');
      // Fallback response c≈©ng c√≥ th·ªÉ streaming
      const fallback = this.getFallbackResponse();
      const words = fallback.split(' ');
      for (let i = 0; i < words.length; i++) {
        onChunk(words[i] + (i < words.length - 1 ? ' ' : ''));
        await new Promise(resolve => setTimeout(resolve, 50)); // 50ms delay
      }
      return;
    }

    try {
      if (this.config.provider === 'localai') {
        console.log('Calling Local AI Stream...');
        await this.callLocalAIStream(message, systemPrompt, onChunk);
        console.log('Local AI Stream completed');
      } else {
        // OpenAI streaming (implement later if needed)
        const response = await this.callOpenAI(message, systemPrompt);
        const words = response.split(' ');
        for (let i = 0; i < words.length; i++) {
          onChunk(words[i] + (i < words.length - 1 ? ' ' : ''));
          await new Promise(resolve => setTimeout(resolve, 50));
        }
      }
    } catch (error) {
      console.error('AI Streaming Service Error:', error);
      const fallback = this.getFallbackResponse();
      const words = fallback.split(' ');
      for (let i = 0; i < words.length; i++) {
        onChunk(words[i] + (i < words.length - 1 ? ' ' : ''));
        await new Promise(resolve => setTimeout(resolve, 50));
      }
    }
  }

  // Fallback response khi AI kh√¥ng kh·∫£ d·ª•ng
  getFallbackResponse() {
    return `Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ Computer Booking System. Hi·ªán t·∫°i t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t.

Tuy nhi√™n, t√¥i c√≥ th·ªÉ cung c·∫•p th√¥ng tin c∆° b·∫£n v·ªÅ h·ªá th·ªëng:

üéØ **T√çNH NƒÇNG CH√çNH:**
‚Ä¢ ƒê·∫∑t l·ªãch s·ª≠ d·ª•ng m√°y t√≠nh
‚Ä¢ Qu·∫£n l√Ω booking c√° nh√¢n  
‚Ä¢ ƒê√°nh gi√° m√°y t√≠nh (1-5 sao)
‚Ä¢ H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ
‚Ä¢ Admin panel ƒë·∫ßy ƒë·ªß

üîß **C√ÄI ƒê·∫∂T:**
‚Ä¢ Y√™u c·∫ßu: Node.js >= 18.0.0
‚Ä¢ Ch·∫°y: npm run dev
‚Ä¢ Admin m·∫∑c ƒë·ªãnh: admin/admin123

B·∫°n c√≥ th·ªÉ li√™n h·ªá admin ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt h∆°n.`;
  }
}

// Export singleton instance
export const aiService = new AIService();
